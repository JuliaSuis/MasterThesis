{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.Series\n",
    "import math\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import statsmodels\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 30, 10\n",
    "rcParams.update({'font.size': 22})\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from matplotlib import pyplot\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression, mutual_info_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load file, print info and select columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to load files\n",
    "def load_file(filepath):\n",
    "    df = pd.read_csv(filepath, sep='\\t', index_col=0, parse_dates=True)\n",
    "    df = df.sort_index()\n",
    "    #we can check that this 2 columns are equal, so we can drop one\n",
    "    #any(df['SALE_AMOUNT_BEFORE_CANCELLATIONS'] != df['SALE_AMOUNT_AFTER_CANCELLATIONS'])\n",
    "    df = df.drop(['SALE_AMOUNT_AFTER_CANCELLATIONS'], axis=1)\n",
    "    df = df.rename(columns={'SALE_AMOUNT_BEFORE_CANCELLATIONS': 'SALE_AMOUNT'})\n",
    "#...\n",
    "    return df.astype('float32')\n",
    "\n",
    "#function to create a new df with selected columns\n",
    "def create_small_df(df, columns):\n",
    "    small_df = df.copy()\n",
    "    small_df = small_df[columns]\n",
    "    return small_df\n",
    "\n",
    "#function to print inf about Data\n",
    "def print_info_df(df, print_columns = False):\n",
    "    #Count period\n",
    "    d1 = df.index[0]\n",
    "    d2 = df.index[-1]\n",
    "    delta = d2 - d1\n",
    "    print('Number of days is ' + str(delta.days) + ' from ' + str(d1) + ' to '+ str(d2))\n",
    "    print('The shape of the data: %d*%d' %(df.shape[0],df.shape[1]))\n",
    "    print('Check for Nan values: %s'%(df.isnull().values.any()))\n",
    "    if (print_columns == True):\n",
    "        print(list(df.columns))\n",
    "    else:\n",
    "        print('Number of columns: %d'%(df.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose data! \n",
    "## Choose feature! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_file('..')\n",
    "print_info_df(df, False)\n",
    "\n",
    "feature = 'SALE_AMOUNT'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Make it Normalized! [0;1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minmax_scaler(df):\n",
    "    scaler = preprocessing.MinMaxScaler(feature_range=(-1, 1))\n",
    "    new_df = df.copy()\n",
    "    new_df[new_df.columns] = scaler.fit_transform(new_df[new_df.columns])\n",
    "    return new_df, scaler\n",
    "\n",
    "def minmax_unscaler(df, scaler):\n",
    "    new_df = df.copy()\n",
    "    new_df[new_df.columns] = scaler.inverse_transform(new_df[new_df.columns])\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaled_df, scaler = minmax_scaler(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename scaled_df -> df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = scaled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create table for results\n",
    "cols = ['features', 'f_regression', 'mutual_f_regression']\n",
    "score_df = pd.DataFrame([], columns=cols)\n",
    "score_df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_f_regression(df, select_n=10):\n",
    "    array = df.values\n",
    "    X = array[:,1:]\n",
    "    Y = array[:,0]\n",
    "    list_features = df.columns[1:]\n",
    "    columns = df.columns\n",
    "    test = SelectKBest(score_func=f_regression, k=select_n)\n",
    "    fit = test.fit(X, Y)\n",
    "    # summarize scores\n",
    "    np.set_printoptions(precision=3)\n",
    "    list_scores = fit.scores_\n",
    "    #features = fit.transform(X)\n",
    "    return list_features, list_scores\n",
    "\n",
    "def calc_mutual_f_regression(df, select_n=10):\n",
    "    array = df.values\n",
    "    X = array[:,1:]\n",
    "    Y = array[:,0]\n",
    "    list_features = df.columns[1:]\n",
    "    columns = df.columns\n",
    "    test = SelectKBest(score_func=mutual_info_regression, k=select_n)\n",
    "    fit = test.fit(X, Y)\n",
    "    # summarize scores\n",
    "    np.set_printoptions(precision=3)\n",
    "    list_scores = fit.scores_\n",
    "    #features = fit.transform(X)\n",
    "    return list_features, list_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_features, scores_f_regression = calc_f_regression(df, 5)\n",
    "scores_f_mutual = calc_mutual_f_regression(df, 5)[1]\n",
    "score_df['features'] = list_features\n",
    "score_df['f_regression'] = [round(a,2) for a in scores_f_regression]\n",
    "score_df['mutual_f_regression'] = [round(a,2) for a in scores_f_mutual]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df.sort_values('f_regression',ascending = False).head(10)[['features','f_regression']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df.sort_values('mutual_f_regression',ascending = False).head(10)[['features','mutual_f_regression']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()[feature].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def forest_regression(df, show_bar=True):\n",
    "    dataframe = df.copy()\n",
    "    array = dataframe.values\n",
    "    # split into input and output\n",
    "    X = array[:,1:]\n",
    "    y = array[:,0]\n",
    "    # fit random forest model\n",
    "    model = RandomForestRegressor(n_estimators=500, random_state=1)\n",
    "    model.fit(X, y)\n",
    "    # show importance scores\n",
    "    l = model.feature_importances_\n",
    "    # plot importance scores\n",
    "    names = dataframe.columns.values[0:-1]\n",
    "    if (show_bar == True):\n",
    "        plt.rcdefaults()\n",
    "        fig, ax = plt.subplots()\n",
    "        y_pos = np.arange(len(names))\n",
    "        performance = l\n",
    "        ax.barh(y_pos, performance)\n",
    "        ax.set_yticks(y_pos)\n",
    "        ax.set_yticklabels(names)\n",
    "        ax.invert_yaxis() \n",
    "        ax.set_xlabel('Importance')\n",
    "        ax.set_title('RandomForestRegressor')\n",
    "        plt.show()\n",
    "    return names, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def view_table_results(names, l, df):\n",
    "    results_df = pd.DataFrame(columns=['feature', 'result'])\n",
    "    #n = list(df.columns)*5\n",
    "    for i in range(len(names)):\n",
    "        results_df.loc[i] = ['%s'%(names[i]), l[i]]\n",
    "    return results_df.sort_values('result', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names, res = forest_regression(df)\n",
    "table = view_table_results(names, res, df)\n",
    "table[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFE + Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def RFE_forest(diff_df):\n",
    "    array = diff_df.values\n",
    "    X = array[:,1:]\n",
    "    y = array[:,1]\n",
    "    # perform feature selection\n",
    "    rfe = RFE(RandomForestRegressor(n_estimators=500, random_state=1), 10)\n",
    "    fit = rfe.fit(X, y)\n",
    "    # report selected features\n",
    "    print('Selected Features:')\n",
    "    names = diff_df.columns.values[0:-1]\n",
    "    for i in range(len(fit.support_)):\n",
    "        if fit.support_[i]:\n",
    "            print(names[i])\n",
    "    # plot feature rank\n",
    "    names = diff_df.columns.values[0:-1]\n",
    "    plt.rcdefaults()\n",
    "    fig, ax = plt.subplots()\n",
    "    y_pos = np.arange(len(names))\n",
    "    performance = fit.ranking_\n",
    "    ax.barh(y_pos, performance)\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(names)\n",
    "    ax.invert_yaxis() \n",
    "    ax.set_xlabel('Importance')\n",
    "    ax.set_title('RandomForestRegressor')\n",
    "    plt.show()\n",
    "    return names, fit.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names, ranking = RFE_forest(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
